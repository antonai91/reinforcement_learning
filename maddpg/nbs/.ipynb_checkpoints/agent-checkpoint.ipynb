{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecological-holmes",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "classical-patch",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugin_write_and_run import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "moral-selection",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run ../src/agent.py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers as opt\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../src\")\n",
    "from config import *\n",
    "from make_env import *\n",
    "from replay_buffer import *\n",
    "from networks import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "anticipated-flesh",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%write_and_run -a ../src/agent.py\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, env, n_agent, actor_lr=ACTOR_LR, critic_lr=CRITIC_LR, gamma=GAMMA, tau=TAU):\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.tau = tau\n",
    "        self.actor_lr = actor_lr\n",
    "        self.critic_lr = critic_lr\n",
    "        \n",
    "        self.actor_dims = env.observation_space[n_agent].shape[0]\n",
    "        self.n_actions = env.action_space[n_agent].n\n",
    "        \n",
    "        self.agent_name = \"agent_number_{}\".format(n_agent)\n",
    "        \n",
    "        self.actor = Actor(\"actor_\" + self.agent_name, self.n_actions)\n",
    "        self.critic = Critic(\"critic_\" + self.agent_name)\n",
    "        self.target_actor = Actor(\"target_actor_\" + self.agent_name, self.n_actions)\n",
    "        self.target_critic = Critic(\"critic_\" + self.agent_name)\n",
    "        \n",
    "        self.actor.compile(optimizer=opt.Adam(learning_rate=actor_lr))\n",
    "        self.critic.compile(optimizer=opt.Adam(learning_rate=critic_lr))\n",
    "        self.target_actor.compile(optimizer=opt.Adam(learning_rate=actor_lr))\n",
    "        self.target_critic.compile(optimizer=opt.Adam(learning_rate=critic_lr))\n",
    "        \n",
    "        actor_weights = self.actor.get_weights()\n",
    "        critic_weights = self.critic.get_weights()\n",
    "        \n",
    "        self.target_actor.set_weights(actor_weights)\n",
    "        self.target_critic.set_weights(critic_weights)\n",
    "        \n",
    "        self.noise = np.random.uniform(size=self.n_actions)\n",
    "        \n",
    "    def update_target_networks(self, tau):\n",
    "        actor_weights = self.actor.weights\n",
    "        target_actor_weights = self.target_actor.weights\n",
    "        for index in range(len(actor_weights)):\n",
    "            target_actor_weights[index] = tau * actor_weights[index] + (1 - tau) * target_actor_weights[index]\n",
    "\n",
    "        self.target_actor.set_weights(target_actor_weights)\n",
    "        \n",
    "        critic_weights = self.critic.weights\n",
    "        target_critic_weights = self.target_critic.weights\n",
    "    \n",
    "        for index in range(len(critic_weights)):\n",
    "            target_critic_weights[index] = tau * critic_weights[index] + (1 - tau) * target_critic_weights[index]\n",
    "\n",
    "        self.target_critic.set_weights(target_critic_weights)\n",
    "        \n",
    "    def get_actions(self, actor_states):\n",
    "        actions = self.actor(actor_states)\n",
    "        actions = actions + self.noise\n",
    "\n",
    "        return actions.numpy()[0]\n",
    "    \n",
    "    def save(self, path_save):\n",
    "        self.actor.save_weights(f\"{path_save}/{self.actor.net_name}.h5\")\n",
    "        self.target_actor.save_weights(f\"{path_save}/{self.target_actor.net_name}.h5\")\n",
    "        self.critic.save_weights(f\"{path_save}/{self.critic.net_name}.h5\")\n",
    "        self.target_critic.save_weights(f\"{path_save}/{self.target_critic.net_name}.h5\")\n",
    "        \n",
    "    def load(self, path_load):\n",
    "        self.actor.load_weights(f\"{path_load}/{self.actor.net_name}.h5\")\n",
    "        self.target_actor.load_weights(f\"{path_load}/{self.target_actor.net_name}.h5\")\n",
    "        self.critic.load_weights(f\"{path_load}/{self.critic.net_name}.h5\")\n",
    "        self.target_critic.load_weights(f\"{path_load}/{self.target_critic.net_name}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "varying-ozone",
   "metadata": {},
   "outputs": [],
   "source": [
    "from make_env import *\n",
    "from replay_buffer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "romance-performance",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = make_env(ENV_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "equivalent-child",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(env, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "governmental-cornell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'critic_agent_number_2'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.critic.net_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "apart-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_state, reward, done, info = env.step([[1, 2, 3, 4, 5], [1, 2, 3, 4, 5], [1, 2, 3, 4, 5]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dental-message",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.71558146, -1.47510576,  0.59780388, -0.6180208 ,  0.71558146,\n",
       "       -1.47510576,  1.30439373,  0.31059763, -0.02751293, -0.36316338])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_state[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "extended-brown",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<networks.Actor at 0x7fbe3122e6a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "hungry-michigan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.4568894, 0.5858264, 0.6161   , 1.2974641, 1.2081289],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.get_actions(actors_state[2][None, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "alien-angola",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actor_dims"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
