{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/\")\n",
    "import gym\n",
    "import random\n",
    "from config import ENV_NAME\n",
    "from process_image import process_image\n",
    "from plugin_write_and_run import write_and_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env = gym.make(ENV_NAME)\n",
    "state = env.reset()\n",
    "state.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ../src/pong_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile ../src/pong_wrapper.py\n",
    "import random\n",
    "import gym\n",
    "import numpy as np\n",
    "from process_image import process_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Appending to ../src/pong_wrapper.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile -a ../src/pong_wrapper.py\n",
    "\n",
    "class PongWrapper(object):\n",
    "    \"\"\"\n",
    "    Wrapper for the environment provided by Openai Gym\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, env_name: str, no_op_steps: int = 10, history_length: int = 4):\n",
    "        self.env = gym.make(env_name)\n",
    "        self.no_op_steps = no_op_steps\n",
    "        self.history_length = 4 # number of frames to put together (we need dynamic to see where the ball is going)\n",
    "\n",
    "        self.state = None\n",
    "        self.last_lives = 0\n",
    "\n",
    "    def reset(self, evaluation: bool = False):\n",
    "        \"\"\"Resets the environment\n",
    "\n",
    "        Arguments:\n",
    "            evaluation: Set to True when we are in evaluation mode, in this case the agent takes a random number of no-op steps if True.\n",
    "        \"\"\"\n",
    "\n",
    "        self.frame = self.env.reset()\n",
    "        self.last_lives = 0\n",
    "\n",
    "        # If in evaluation model, take a random number of no-op steps\n",
    "        if evaluation:\n",
    "            for _ in range(random.randint(0, self.no_op_steps)):\n",
    "                self.env.step(1)\n",
    "\n",
    "        # For the initial state, we stack the first frame four times\n",
    "        self.state = np.repeat(process_image(self.frame), self.history_length, axis=2)\n",
    "\n",
    "    def step(self, action: int, render_mode=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            action: An integer describe action to take\n",
    "            render_mode: None doesn't render anything, 'human' renders the screen in a new window, 'rgb_array' returns also an np.array with rgb values\n",
    "\n",
    "        Returns:\n",
    "            processed_image: The processed new frame as a result of that action\n",
    "            reward: The reward for taking that action\n",
    "            terminal: Whether the game has ended\n",
    "            new_frame: The raw new frame as a result of that action\n",
    "        \"\"\"\n",
    "        new_frame, reward, terminal, info = self.env.step(action)\n",
    "\n",
    "        processed_image = process_image(new_frame)\n",
    "\n",
    "        self.state = np.append(self.state[:, :, 1:], processed_image, axis=2) # replace the first observation of the previous state with the last one\n",
    "\n",
    "        if render_mode == 'rgb_array':\n",
    "            return processed_image, reward, terminal, self.env.render(render_mode)\n",
    "        elif render_mode == 'human':\n",
    "            self.env.render(render_mode)\n",
    "\n",
    "        return processed_image, reward, terminal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
